# Module 01 â€” AI Ops Foundations

Welcome to **Module 01**, the foundation of AI in IT Operations.  
This module establishes **core principles, risk zones, and operational mental models** that every team must understand before introducing AI into their systems.

---

## Table of Contents

1. [Introduction](#introduction)  
2. [Video Lessons](#video-lessons)  
3. [Traffic-Light Risk Zones for AI Usage](#traffic-light-risk-zones-for-ai-usage)  
4. [AI Ops Core Principles](#ai-ops-core-principles)  
5. [Diagrams](#diagrams)  
6. [Next Steps](#next-steps)

[â¬… Return to Module Index](../MODULE_INDEX.md)

---

## Introduction

AI in IT Operations is **not a tooling problem â€” itâ€™s a systems problem**.  
Without proper governance and controls, AI can generate operational risk rather than reduce it.

In this module, you will learn:

- What AI Ops is and isnâ€™t  
- Why **human accountability** remains critical  
- How to classify AI usage risk with a **traffic-light model**  
- The **core principles** that govern safe AI operations

---

## Video Lessons

### ðŸŽ¥ Video 01A â€” What AI Ops Is (and Is Not)

[â–¶ Watch Video 01A](https://share.synthesia.io/fc5bf771-3784-44e3-9e28-021c5e83f7a8)

**Diagram cue:** `ai-ops-foundation-architecture.png`  
> Review the foundational architecture as you watch.

---

### ðŸŽ¥ Video 01B â€” Human-in-the-Loop & Accountability

[â–¶ Watch Video 01B](https://share.synthesia.io/83062c5b-39a2-4a4f-bbb5-46ff3ed63e0e)

**Key concepts:**

- Humans remain accountable even when AI is executing tasks  
- Automation without oversight can scale outages  
- Control points must be defined before AI interacts with production

**Diagram cue:** `ai-incident-lifecycle.png`

---

### ðŸŽ¥ Video 01C â€” AI Usage Risk Zones (Traffic-Light Model)

[â–¶ Watch Video 01C](https://share.synthesia.io/104a65d2-0871-4a15-8678-f580c95ed5e5)

| Zone  | Description | Examples |
|-------|------------|---------|
| Green | Low-risk, advisory | Ticket summarization, knowledge retrieval |
| Yellow| Medium-risk, drafts tasks | Script drafting, runbook suggestions |
| Red   | High-risk, no AI execution | Direct access changes, automated deployment without approval |

**Diagram cue:** `ai-ticket-handling-flow.png`

---

### ðŸŽ¥ Video 01D â€” AI Ops Core Principles

[â–¶ Watch Video 01D](https://share.synthesia.io/35ac2298-3f7b-4bea-8827-7c89c3a9cba6)

**Core Principles:**

| Principle | Description |
|-----------|-------------|
| Human-in-the-loop | Humans remain accountable |
| Controlled autonomy | Automation must have clear boundaries |
| Continuous review | AI decisions are audited |
| Governance first | Policies define allowed AI usage |

**Diagram cue:** `ai-governance-operating-model.png`  

---

## Diagrams

All diagrams for this module are located in the `diagrams/` folder:

- `ai-ops-foundation-architecture.png`  
- `ai-incident-lifecycle.png`  
- `ai-ticket-handling-flow.png`  
- `documentation-feedback-loop.png`  
- `ai-automation-boundary-flow.png`  
- `ai-governance-operating-model.png`  

> Click to view full-size versions.

---

## Next Steps

After completing Module 01:

1. Proceed to [Module 02 â€” AI in Incidents & Tickets](../MODULE_02_AI_IN_INCIDENTS/README.md)  
2. Review diagrams as you watch videos  
3. Return to Module Index anytime: [â¬… Return to Module Index](../MODULE_INDEX.md)

---

**Tip:** Each video includes a **diagram cue**. Open the diagram file while watching for maximum clarity.


